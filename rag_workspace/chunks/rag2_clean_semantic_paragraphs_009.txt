Open-domain QA Performance
Table 5 shows the evaluation results with LLaMA-
2-7B as the language model. Across different re-
trievers, we observe higher QA performance in
terms of the EM@l metric on average when using
propositions as the retrieval unit.
Using propositions rather than passages in the
prompts, the four dense retrievers—SimCSE, Con-
Retriever, DPR, and GTR—improve by +4.1, +3.2,
+2.7, and +2.8 in the EM@500 score. The improve-
ments for using sentences over passages for the
four retrieval models are +2.4, +2.1, +2, and +1.6,
respectively. It is interesting to note that in the
LLaMA-2-7B model, the QA accuracy on TQA
and WebQ is not sensitive to retrieval type. The
highest improvements over the closed-book setting
are only +4.9 and +3.2, achieved by GTR with
propositions. Nevertheless, we observe that using
sentences and propositions in the prompts results
in higher performance than using passages for all
retrieval models on these two datasets. The results
suggest that using finer-grained units in the prompts
is beneficial to retrieval-augmented generation.

Finer-grained Granularity ⇒Higher
Density of Question-Related Information
Intuitively, compared to sentences or passages as
retrieval units, the advantage of propositions is that
the retrieved propositions have a higher density
of relevant information to the query. With finer-
grained retrieval units, the correct answer to the
query would more likely appear in the top-l re-
trieved words by a dense retriever.
We illustrate this phenomenon by an analysis
shown in Figure 4. Here, we investigate the posi-
tion at which the ground truth answer appears in
the top-l retrieved words. Specifically, we calcu-
late the recall of the gold answer within the initial l
retrieved words with GTR working with Wikipedia
indexed in three different granularities.
We show the results in Figure 4 and 7 with l
ranging from 0 to 500 across all five datasets. For
a fixed word retrieval budget, proposition retrieval
shows a higher success rate than sentence and pas-
sage retrieval methods. The largest improvement of
proposition retrieval over passage retrieval occurs
within the range of 100-200 words, which corre-
sponds to roughly 10 propositions, 5 sentences, or
2 passages. As word count increases, the recall rate
of the three granularities converges, encompassing
all relevant information.
Related Work
Recent works on dense retrievers typically adopt
a dual-encoder architecture (Yih et al., 2011;
Reimers and Gurevych, 2019; Karpukhin et al.,
2020; Ni et al., 2022).
With dual-encoders,
each query and document is encoded into a low-
dimensional feature vector respectively, and their
relevance is measured by a non-parametric similar-
ity function between the embedding vectors (Muss-
mann and Ermon, 2016). Due to the limited expres-
sivity from the similarity function, dual encoder
models often generalize poorly to new tasks with
scarce training data (Thakur et al., 2021). Previous
studies use techniques such as data augmentation
(Wang et al., 2022; Yu et al., 2023a; Izacard et al.,
2022; Gao and Callan, 2022; Lin et al., 2023; Dai
et al., 2023), continual pre-training (Chang et al.,
2020; Sachan et al., 2021; Oguz et al., 2022), task-
aware training (Xin et al., 2022; Cheng et al., 2023),
hybrid sparse-dense retrieval (Luan et al., 2021;
Chen et al., 2022), or mixed strategy retrieval (Ma
et al., 2022, 2023) and so on to improve cross-task
generalization performance of dense retrievers.
--- Page 8 ---