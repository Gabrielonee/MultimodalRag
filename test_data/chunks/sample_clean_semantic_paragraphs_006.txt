RAG excels in dynamic environments by offering real-
time knowledge updates and effective utilization of external
knowledge sources with high interpretability. However, it
comes with higher latency and ethical considerations regarding
data retrieval. On the other hand, FT is more static, requiring
retraining for updates but enabling deep customization of the
model’s behavior and style. It demands significant compu-
tational resources for dataset preparation and training, and
while it can reduce hallucinations, it may face challenges with
unfamiliar data.
In multiple evaluations of their performance on various
knowledge-intensive tasks across different topics, [28] re-
vealed that while unsupervised fine-tuning shows some im-
provement, RAG consistently outperforms it, for both exist-
ing knowledge encountered during training and entirely new
knowledge. Additionally, it was found that LLMs struggle
to learn new factual information through unsupervised fine-
tuning. The choice between RAG and FT depends on the
specific needs for data dynamics, customization, and com-
putational capabilities in the application context. RAG and
FT are not mutually exclusive and can complement each
other, enhancing a model’s capabilities at different levels.
In some instances, their combined use may lead to optimal
performance. The optimization process involving RAG and FT
may require multiple iterations to achieve satisfactory results.
III. RETRIEVAL
In the context of RAG, it is crucial to efficiently retrieve
relevant documents from the data source. There are several
key issues involved, such as the retrieval source, retrieval
granularity, pre-processing of the retrieval, and selection of
the corresponding embedding model.
A. Retrieval Source
RAG relies on external knowledge to enhance LLMs, while
the type of retrieval source and the granularity of retrieval
units both affect the final generation results.
1) Data Structure: Initially, text is s the mainstream source
of retrieval. Subsequently, the retrieval source expanded to in-
clude semi-structured data (PDF) and structured data (Knowl-
edge Graph, KG) for enhancement. In addition to retrieving
from original external sources, there is also a growing trend in
recent researches towards utilizing content generated by LLMs
themselves for retrieval and enhancement purposes.

--- Page 6 ---

SUMMARY OF RAG METHODS

Retrieval Source

Granularity
Augmentation

Pre-training

DenseX [30]
FactoidWiki

Proposition

Dataset-base

UPRISE [20]
Dataset-base

Dataset-base

Self-Mem [17]
Dataset-base

Search Engine,Wikipedia

Dataset-base

Filter-rerank [36]
Synthesized dataset

Dataset-base

Sentence Pair

Dataset-base

Sentence Pair

Dataset-base

Pre-training

LM-Indexer [40]
Dataset-base

Dataset-base

CT-RAG [41]
Synthesized dataset

Wikipedia, Common Crawl

Pre-training

Pre-training

RETRO++ [44]
Pre-training Corpus

Pre-training

INSTRUCTRETRO [45]
Pre-training corpus

Pre-training

Search Engine